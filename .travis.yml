# Docker on Travis requires sudo.
sudo: required

# Based on http://lmjohns3.com/2015/06/using-travis-ci-with-miniconda-scipy-and-nose.html
# Tweaked to specify versions on everything for stability.
language: python
python:
  - "2.7"
services:
  - docker
cache: apt # I don't think caching happens with sudo turned on, so this is a no-op.
addons:
  apt:
    packages: # Since we've turned on sudo, apt-get is available, but this works, too.
    - libatlas-dev
    - libatlas-base-dev
    - liblapack-dev
    - gfortran

before_install:
  - wget http://repo.continuum.io/miniconda/Miniconda2-4.2.12-Linux-x86_64.sh -O miniconda.sh
  - bash miniconda.sh -b -p $HOME/miniconda
  - export PATH="$HOME/miniconda/bin:$PATH"
  # Prefer stability to having the latest
  #- conda update --yes conda

install:
  - conda install --yes python=$TRAVIS_PYTHON_VERSION cython==0.25.2 numpy=1.11.2
  - pip install clodius==0.3.2
  - pip install -r requirements.txt
  - python manage.py migrate

script:
  - set -e
  ### Build and test from the inside out:
  ### 1) Unit tests

  - COOL=dixon2012-h1hesc-hindiii-allreps-filtered.1000kb.multires.cool
  - HITILE=wgEncodeCaltechRnaSeqHuvecR1x75dTh1014IlnaPlusSignalRep2.hitile
  - ANNO=gene_annotations.short.db
  - HIBED=cnv_short.hibed
  - AHBED=arrowhead_domains_short.txt.multires.db
  - HLBED=hiccups_loops_short.txt.multires.db

  - wget https://s3.amazonaws.com/pkerp/public/$COOL    && mv $COOL data/
  - wget https://s3.amazonaws.com/pkerp/public/$HITILE  && mv $HITILE data/
  - wget https://s3.amazonaws.com/pkerp/public/$ANNO    && mv $ANNO data/
  - wget https://s3.amazonaws.com/pkerp/public/$HIBED   && mv $HIBED data/
  - wget https://s3.amazonaws.com/pkerp/public/$AHBED   && mv $AHBED data/
  - wget https://s3.amazonaws.com/pkerp/public/$HLBED   && mv $HLBED data/

  - echo 'foo bar' > data/tiny.txt
  - python manage.py test tilesets

  ### 2) Django server

  - PORT=6000
  - python manage.py runserver localhost:$PORT &
  - URL="http://localhost:$PORT/tilesets/"
  - until $(curl --output /dev/null --silent --fail --globoff $URL); do echo '.'; sleep 1; done

  - curl -F "datafile=@data/$COOL" -F "filetype=cooler" -F "datatype=matrix" -F "uid=aa" $URL
  - curl -F "datafile=@data/$HITILE" -F "filetype=hitile" -F "datatype=vector" -F "uid=bb" $URL
  # TODO: Check that the output is what we expect?

  ### 3) nginx server

  - pip install uwsgi
  - uwsgi --http :7000 --module api.wsgi & #--pythonpath `python -c "import site; print(' '.join(site.getsitepackages()))"`
  # I get: "unable to load configuration from /home/travis/miniconda/lib/site-python"
  # uwsgi is python: Wouldn't it already know the path?
  - apt-get install zlib1g-dev
  - apt-get install uwsgi-plugin-python
  # TODO: Are any of these necessary here?
  #- pip install djangorestframework django-rest-swagger django-cors-headers pygments h5py
  #- pip install pandas cooler clodius django-guardian slugid
  - apt-get install nginx
  - cp hgserver_nginx.conf /etc/nginx/sites-enabled/

  # TODO: I don't see where the highglass ui server is actually referenced?
  # TODO: pin to release
  - git clone --depth 1 https://github.com/hms-dbmi/higlass.git
  - pushd higlass
  - npm install
  # TODO: Anything else needed here?
  - popd

  - /etc/init.d/nginx restart

  # Original had --virtualenv /home/ubuntu/.virtualenvs/hg-server/
  # TODO: I'm confused here: What's the relationship between this uwsgi call and the one above?
  - uwsgi --socket :8000 --plugins python --module higlass_server.wsgi --workers 2 &
  # TODO: test this

  ### 4) Docker

  - docker login -u $DOCKER_USER -p $DOCKER_PASS
  - docker build --tag gehlenborglab/higlass-server:latest .
  # minimal tests
  - docker run --name my-higlass-server --detach --publish 8001:8000 higlass-server
  - JSON=`curl http://localhost:8001/`
  - '[ "$JSON" == "{\"tilesets\":\"http://localhost:8001/tilesets/\"}" ] && echo "Got expected response. Yay!"'

  # TODO: Probably not what we want?
  - if [ "$TRAVIS_EVENT_TYPE" == 'pull_request' ]
  -   then docker push gehlenborglab/higlass-server
  - fi